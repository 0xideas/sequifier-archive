x testing auto regression
x more memory efficient preprocessing
x shuffle data during training

x replace batch resizing with dynamic axes -> not possible unless I give up dict as model input
make underscore and dash usage consistent
make query/loc consistent
make tests smaller
systematize hparams or self access for hyperparameters in train.py


add exporting to pickle and gpu inference/(make onnx a flag)
add dynamic preprocessing on training
implement early stopping if validation error doesn't improve over x epochs
(use uv instead of pip)
file formats other than csv? -> yes, parquet, for compression


x adding export batch size (only if dynamic axes is not working)
add gradient accumulation
columns to use for training and inference as config parameters
compile model using torch.compile or thunder (just released)

