{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import TransformerModel\n",
    "from transformer_config import load_transformer_config\n",
    "from preprocessor import Preprocessor, numpy_to_pytorch, load_preprocessor_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seq_length': 10,\n",
       " 'n_classes': 3288,\n",
       " 'training_data_path': './data/ratings-split0.csv',\n",
       " 'validation_data_path': './data/ratings-split0.csv',\n",
       " 'model_spec': {'d_model': 50, 'nhead': 2, 'd_hid': 50, 'nlayers': 2},\n",
       " 'training_spec': {'device': 'cpu',\n",
       "  'epochs': 1,\n",
       "  'iter_save': 10,\n",
       "  'batch_size': 50,\n",
       "  'lr': 0.001,\n",
       "  'dropout': 0.3,\n",
       "  'criterion': 'CrossEntropyLoss',\n",
       "  'optimizer': {'name': 'Adam'},\n",
       "  'scheduler': {'name': 'StepLR', 'step_size': 1.0, 'gamma': 0.99}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_config = load_transformer_config(\"./configs/transformer/default.yaml\")\n",
    "model = TransformerModel(transformer_config)\n",
    "transformer_config.dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_config = load_preprocessor_config(\"./configs/preprocessor/default.yaml\")\n",
    "preprocessor = Preprocessor(**preprocessor_config.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = numpy_to_pytorch(preprocessor.splits[0], preprocessor_config.seq_length, transformer_config.training_spec.device)\n",
    "X_valid, y_valid = numpy_to_pytorch(preprocessor.splits[1], preprocessor_config.seq_length, transformer_config.training_spec.device)\n",
    "X_test, y_test = numpy_to_pytorch(preprocessor.splits[2], preprocessor_config.seq_length, transformer_config.training_spec.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time:  5.34s | valid loss  1.81 | valid ppl     6.12\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/projects/sequifier/transformer.py:223: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  x = x + self.pe[:x.size(0)]\n"
     ]
    }
   ],
   "source": [
    "model.train_model(X_train, y_train, X_valid, y_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inferer_config import load_inferer_config\n",
    "inferer_config = load_inferer_config(\"./configs/inferer/default.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.4729342 ,  1.299694  ,  0.54408395, ..., -1.3184454 ,\n",
       "        -2.5099525 , -3.4055407 ],\n",
       "       [-4.854726  ,  0.76395094,  0.0486614 , ..., -1.1098588 ,\n",
       "        -2.9533162 , -3.3575296 ],\n",
       "       [-5.4430447 ,  0.95491594,  0.22478807, ..., -1.398021  ,\n",
       "        -2.8561687 , -4.1762753 ],\n",
       "       ...,\n",
       "       [-5.227994  ,  0.68309355,  0.1911543 , ..., -1.5813189 ,\n",
       "        -2.539854  , -4.082448  ],\n",
       "       [-5.689005  ,  0.9216385 ,  0.34630784, ..., -1.9468362 ,\n",
       "        -2.665267  , -3.8618102 ],\n",
       "       [-5.4838233 ,  0.8872019 , -0.13988963, ..., -1.429875  ,\n",
       "        -2.951868  , -3.9098978 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inferer import Inferer\n",
    "\n",
    "inferer = Inferer(\"models/sequifier-4eecb3ee-best.onnx\")\n",
    "x_test = X_test.detach().cpu().numpy()\n",
    "probs = inferer.infer_probs(x_test.T)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
