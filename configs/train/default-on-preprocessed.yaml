#data driven config path
ddconfig_path: "/configs/ddconfigs/chr8.json" # 'data driven' config path, written to by preprocessing step

model_name:  # model name to load from in case there are checkpoints of that model available
#data specification
seq_length: 50 # length of sequence used for classification, cannot be larger than sew_length in the preprocessing step

#model specification
model_spec:
  d_model: 50 # dimensionality of the token embedding system
  nhead: 2 # number of attention heads within each transformer layer
  d_hid: 50 # dimensionality of feedforward network inside transformer layer
  nlayers: 2 # number of transformer layers

#training specification
training_spec:
  device: "cpu" # device for model training
  epochs: 3 # number of epochs
  iter_save: 1 # frequency of checkpointing
  batch_size: 50 # batch size for training
  lr: 0.003  # learning rate
  dropout: 0.3 # dropout rate during training
  criterion: "CrossEntropyLoss" # loss function, can be any in torch.nn
  optimizer: 
    name: "Adam" # optimizer, can be any on torch.optim
  scheduler:
    name: "StepLR" # learning rate scheduler, can be any in torch.optim.lr_scheduler
    step_size: 1.0
    gamma: 0.99
