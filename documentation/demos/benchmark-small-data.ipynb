{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_227486/2162656668.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate random sequences of length 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(101)\n",
    "seqs = np.random.choice(10, size=(20000, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate target based on the sum of fields 1-3 and 4-6, multiplied by fields 8-10. Field 7 is ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.sum((seqs[:,:3] + seqs[:,:3:6]) * seqs[:,-3:], axis=1)\n",
    "target = (v/(np.max(v)/15)).astype(int)\n",
    "target[target>9] = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check target label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1590\n",
       "1    2860\n",
       "2    3303\n",
       "3    3120\n",
       "4    2596\n",
       "5    2129\n",
       "6    1577\n",
       "7    1200\n",
       "8     710\n",
       "9     915\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(target).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequenceId</th>\n",
       "      <th>subsequenceId</th>\n",
       "      <th>inputCol</th>\n",
       "      <th>10</th>\n",
       "      <th>9</th>\n",
       "      <th>8</th>\n",
       "      <th>7</th>\n",
       "      <th>6</th>\n",
       "      <th>5</th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>itemId</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>itemId</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>itemId</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>itemId</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>itemId</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequenceId  subsequenceId inputCol  10  9  8  7  6  5  4  3  2  1  target\n",
       "0           0              0   itemId   1  6  7  9  8  4  8  5  0  5       1\n",
       "1           1              1   itemId   8  1  3  8  3  3  2  8  9  3       8\n",
       "2           2              2   itemId   7  0  9  7  9  8  4  3  3  7       5\n",
       "3           3              3   itemId   4  8  7  6  9  4  2  7  7  7       7\n",
       "4           4              4   itemId   0  4  1  8  3  1  8  4  3  2       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = {\n",
    "    \"sequenceId\": np.arange(20000),\n",
    "    \"subsequenceId\": np.arange(20000),\n",
    "    \"inputCol\": np.repeat(\"itemId\", 20000)\n",
    "}\n",
    "for i in range(10):\n",
    "    data_dict[str(10-i)] = seqs[:,i]\n",
    "\n",
    "data_dict[\"target\"] = target\n",
    "data = pd.DataFrame(data_dict)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write train and test data to separate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = \"/home/leon/projects/test-sequifier\"\n",
    "data.iloc[:10000,:].to_csv(f\"{project_path}/train_data.csv\", sep=\",\", decimal=\".\", index=None)\n",
    "data.iloc[10000:,:].to_csv(f\"{project_path}/test_data.csv\", sep=\",\", decimal=\".\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a model on train data using the sequifier cli and infer on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.yaml\n",
    "# \n",
    "# project_path: \"/home/leon/projects/test-sequifier\"\n",
    "# #metadata\n",
    "# n_classes: 10 # number of classes\n",
    "# training_data_path: \"/home/leon/projects/test-sequifier/train_data.csv\" # absolute path to training data\n",
    "# validation_data_path: \"/home/leon/projects/test-sequifier/train_data.csv\" # absolute path to validation data\n",
    "# \n",
    "# target_column: itemId\n",
    "# target_column_type: categorical\n",
    "# column_types: {\n",
    "#   itemId: int64\n",
    "# }\n",
    "# n_classes: {\n",
    "#   itemId: 10\n",
    "# }\n",
    "# categorical_columns: [\"itemId\"]\n",
    "# real_columns: []\n",
    "# \n",
    "# model_name: \"default\"  # model name to load from in case there are checkpoints of that model available, can be None\n",
    "# #data specification\n",
    "# seq_length: 10 # length of sequence used for classification, cannot be larger than sew_length in the preprocessing step\n",
    "# log_interval: 100\n",
    "# #model specification\n",
    "# model_spec:\n",
    "#   d_model: 50 # dimensionality of the token embedding system\n",
    "#   nhead: 2 # number of attention heads within each transformer layer\n",
    "#   d_hid: 50 # dimensionality of feedforward network inside transformer layer\n",
    "#   nlayers: 2 # number of transformer layers\n",
    "# \n",
    "# #training specification\n",
    "# training_spec:\n",
    "#   device: \"cpu\" # device for model training\n",
    "#   epochs: 500 # number of epochs\n",
    "#   iter_save: 50 # frequency of checkpointing\n",
    "#   batch_size: 50 # batch size for training\n",
    "#   lr: 0.0005  # learning rate\n",
    "#   dropout: 0.3 # dropout rate during training\n",
    "#   criterion: \"CrossEntropyLoss\" # loss function, can be any in torch.nn\n",
    "#   optimizer: \n",
    "#     name: \"Adam\" # optimizer, can be any on torch.optim\n",
    "#   scheduler:\n",
    "#     name: \"StepLR\" # learning rate scheduler, can be any in torch.optim.lr_scheduler\n",
    "#     step_size: 1.0\n",
    "#     gamma: 0.993\n",
    "#   continue_training: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(\n",
    "    f\"sequifier --train --config-path={project_path}/configs/train.yaml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer.yaml\n",
    "# project_path: \"/home/leon/projects/test-sequifier\"\n",
    "# #data driven config path\n",
    "# target_column: itemId\n",
    "# target_column_type: categorical\n",
    "# column_types: {\n",
    "#   itemId: int64\n",
    "# }\n",
    "# n_classes: {\n",
    "#   itemId: 10\n",
    "# }\n",
    "# categorical_columns: [\"itemId\"]\n",
    "# real_columns: []\n",
    "# \n",
    "# inference_data_path: \"/home/leon/projects/test-sequifier/test_data.csv\" # path to validation data (within project folder)\n",
    "# model_path: \"models/sequifier-default-best.onnx\" # path to model (within project folder)\n",
    "# batch_size: 50\n",
    "# device: \"cpu\" # device used for inference\n",
    "# seq_length: 10 # sequence length for prediction (must be identical to training)\n",
    "# output_probabilities: True # write out class probablities for further processing\n",
    "# ddconfig_path: \"configs/ddconfigs/chr8.json\" # data driven config path, or path to any json that contains {{'id_map':{label1:index1, ..., }}}, can be none if map_to_id is false\n",
    "# map_to_id: False # map predictions from indices to labels (requires ddconfig_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferring for sequifier-default-best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/projects/sequifier/src/sequifier/infer.py:92: RuntimeWarning: overflow encountered in exp\n",
      "  np.sum(np.exp(ort_outs), axis=1), ort_outs.shape[1]\n",
      "/home/leon/projects/sequifier/src/sequifier/infer.py:94: RuntimeWarning: overflow encountered in exp\n",
      "  probs = np.exp(ort_outs) / normalizer\n",
      "/home/leon/projects/sequifier/src/sequifier/infer.py:94: RuntimeWarning: invalid value encountered in divide\n",
      "  probs = np.exp(ort_outs) / normalizer\n",
      "/home/leon/miniconda3/envs/dev/lib/python3.11/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing probabilities to /home/leon/projects/test-sequifier/outputs/probabilities/sequifier-default-best_probabilities.csv\n",
      "Writing predictions to /home/leon/projects/test-sequifier/outputs/predictions/sequifier-default-best_predictions.csv\n",
      "Inference complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\n",
    "f\"sequifier --infer --config-path={project_path}/configs/infer.yaml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load predictions from inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.read_csv(f\"{project_path}/outputs/predictions/sequifier-default-best_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate transformer test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8469"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(target[10000:] == preds[\"0\"].values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and evaluate random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6419"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=1000)\n",
    "rf.fit(data.iloc[:10000,3:-1], data.iloc[:10000,-1])\n",
    "rf_preds = rf.predict(data.iloc[10000:,3:-1])\n",
    "np.mean(rf_preds==target[10000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and evaluate XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6967"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "D_train = xgb.DMatrix(data.iloc[:10000,3:-1].values, label=data.iloc[:10000,-1].values)\n",
    "D_test = xgb.DMatrix(data.iloc[10000:,3:-1].values, label=data.iloc[10000:,-1].values)\n",
    "param = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 5,  \n",
    "    'objective': 'multi:softprob',  \n",
    "    'num_class': 10\n",
    "} \n",
    "\n",
    "steps = 1000  # The number of training iterations\n",
    "model = xgb.train(param, D_train, steps)\n",
    "\n",
    "xg_preds = model.predict(D_test)\n",
    "xg_best_preds = np.asarray([np.argmax(line) for line in xg_preds])\n",
    "np.mean(xg_best_preds==target[10000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and evaluate logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5663"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "encoder = OneHotEncoder()\n",
    "X_encoded = encoder.fit_transform(data.iloc[:,3:-1])\n",
    "lr = LogisticRegression(penalty='l2', max_iter=10000)\n",
    "lr.fit(X_encoded[:10000,:], target[:10000])\n",
    "lr_preds = lr.predict(X_encoded[10000:,:])\n",
    "np.mean(lr_preds==target[10000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sequifier-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad64dbc0878696d9b422cb07e63deba6d531b70d397a0e11e1b180ef0a0a6bf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
